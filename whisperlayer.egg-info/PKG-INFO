Metadata-Version: 2.4
Name: whisperlayer
Version: 1.0.0b0
Summary: WhisperLayer - Linux Native Speech-to-Text Voice Typing with Whisper AI
Author: WhisperLayer Contributors
License: MIT
Project-URL: Homepage, https://github.com/whisperlayer/whisperlayer
Project-URL: Documentation, https://github.com/whisperlayer/whisperlayer#readme
Project-URL: Repository, https://github.com/whisperlayer/whisperlayer
Project-URL: Issues, https://github.com/whisperlayer/whisperlayer/issues
Keywords: speech-to-text,voice-typing,whisper,linux,accessibility,whisperlayer
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: X11 Applications :: GTK
Classifier: Intended Audience :: End Users/Desktop
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Accessibility
Classifier: Topic :: Multimedia :: Sound/Audio :: Speech
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai-whisper>=20231117
Requires-Dist: sounddevice>=0.4.6
Requires-Dist: numpy>=1.24.0
Requires-Dist: pynput>=1.7.6
Requires-Dist: PyGObject>=3.44.0
Requires-Dist: PyQt5>=5.15.0
Requires-Dist: torch>=2.0.0
Requires-Dist: pulsectl>=23.5.0
Requires-Dist: evdev>=1.6.0
Requires-Dist: rapidfuzz>=3.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: license-file

# WhisperLayer üé§

**Linux Native Speech-to-Text Voice Typing**

Transform your voice into text anywhere on your Linux desktop. Press a hotkey, speak, and your words appear where your cursor is.

![Python 3.10+](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Platform: Linux](https://img.shields.io/badge/Platform-Linux-orange)

## ‚ú® Features

- **üéØ Type Anywhere** - Works in any application (browsers, editors, terminals)
- **üß† Whisper AI** - OpenAI's state-of-the-art speech recognition
- **‚ö° GPU Accelerated** - NVIDIA (CUDA) and AMD (ROCm) GPU support
- **üîí Privacy First** - 100% offline, no cloud services
- **‚å®Ô∏è Global Hotkey** - Configurable keyboard shortcut
- **üéöÔ∏è Live Streaming** - Real-time transcription as you speak
- **üñ•Ô∏è Multi-Monitor** - Scales correctly on multi-monitor setups
- **üîß System Tray** - Minimal, unobtrusive interface

## üì¶ Installation

### Quick Install (Recommended)

```bash
# Clone the repository
git clone https://github.com/your-username/whisperlayer.git
cd whisperlayer

# Run the installer
chmod +x install.sh
./install.sh
```

The installer will:
- Install system dependencies (auto-detects Ubuntu/Fedora/Arch)
- Create a Python virtual environment
- Install all Python dependencies
- Add you to the `input` group (for global hotkeys)
- Create a desktop launcher
- Set up systemd service for auto-start

### Manual Installation

```bash
# Prerequisites (Ubuntu/Debian)
sudo apt install python3-venv python3-pip python3-gi portaudio19-dev python3-pyqt5

# For NVIDIA GPU support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# For AMD GPU support (ROCm)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6

# Clone and install
git clone https://github.com/your-username/whisperlayer.git
cd whisperlayer
pip install -e .
```

## üöÄ Usage

### Starting WhisperLayer

**From Applications Menu:**
Search for "WhisperLayer" in your applications menu.

**From Terminal:**
```bash
whisperlayer
```

**As a Service:**
```bash
systemctl --user start whisperlayer
```

### Using Voice Typing

1. **Click** in any text field where you want to type
2. **Press** the hotkey (default: `Ctrl+Alt+F`)
3. **Speak** - your words are transcribed in real-time
4. **Stop speaking** - after 1.5s silence, text is typed automatically

The tray icon indicates recording status:
- üî¥ Red = Recording
- ‚ö´ Grey = Idle

### Settings

Right-click the tray icon ‚Üí **Settings** to configure:

| Setting | Description |
|---------|-------------|
| **Model** | Whisper model size (tiny/base/small/medium/large/turbo) |
| **Device** | GPU acceleration (auto/cuda/cpu) |
| **Hotkey** | Custom keyboard shortcut |
| **Silence Duration** | Auto-stop timeout |
| **Input Device** | Microphone selection |
| **Auto-start** | Launch on login |

## üéØ Whisper Models

| Model | VRAM | Speed | Accuracy | Best For |
|-------|------|-------|----------|----------|
| `tiny` | ~1GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê | Quick notes, low-end hardware |
| `base` | ~1GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | General use |
| `small` | ~2GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Good balance |
| `medium` | ~5GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Better accuracy |
| `large` | ~10GB | üê¢ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Best accuracy |
| **`turbo`** | ~6GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | **Recommended** |

## üîß Troubleshooting

### Hotkey Not Working

Ensure you're in the `input` group:
```bash
groups | grep input
# If not present:
sudo usermod -aG input $USER
# Log out and back in
```

### No GPU Acceleration

Check CUDA/ROCm is working:
```bash
python3 -c "import torch; print(torch.cuda.is_available())"
```

### Audio Issues

List available microphones:
```bash
python3 -c "import sounddevice; print(sounddevice.query_devices())"
```

### Wayland Compatibility

WhisperLayer works on Wayland but requires `ydotool` for text injection:
```bash
sudo apt install ydotool
```

## üìã Requirements

- **OS:** Linux (Ubuntu 22.04+, Fedora 38+, Arch)
- **Python:** 3.10 or newer
- **GPU (optional):** NVIDIA with CUDA 11.8+ or AMD with ROCm 5.6+
- **RAM:** 4GB minimum, 8GB+ recommended
- **Microphone:** Any input device

## ü§ù Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

## üôè Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition model
- [PyTorch](https://pytorch.org/) - Deep learning framework
- [GTK](https://www.gtk.org/) - Settings UI framework

---

**Made with ‚ù§Ô∏è for the Linux community**
